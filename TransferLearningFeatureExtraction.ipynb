{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d85e48",
   "metadata": {},
   "source": [
    "# Transfer Learning - Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708ea4e",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<font size = 4>\n",
    "    \n",
    "Use *`state of the art`* image classification models from Tensorflow Hub<br><br>\n",
    "</font>\n",
    "\n",
    "</font>\n",
    "\n",
    "<font size = 3>\n",
    "Here we are going to leverage image classification weights that are learnt by these predefined models, <br>\n",
    "    \n",
    "**Following is included here:<br>**\n",
    "    \n",
    "- `Load & Prepare` training and test images<br>\n",
    "- `Identify` location of the predefined model\n",
    "- `Create` model that will be applied to our data\n",
    "- `Train & Evaluate` model\n",
    "- `Explore` model performance\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a417e8",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062941b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of data\n",
    "dpath = \"../datasets/FoodClasses/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the directories in dataset\n",
    "for dirpath, dirnames, filenames in os.walk(dpath):\n",
    "    print(f\"{len(dirnames)} directores and {len(filenames)} images in '{dirpath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5ca67",
   "metadata": {},
   "source": [
    "<font size = 4>\n",
    "    \n",
    "**Note:**<br>\n",
    "- Training directories have `75 images` each where as the test directories have `250 images` each\n",
    "- Training on `less data`, but evaluation has `more data`\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba94e4",
   "metadata": {},
   "source": [
    "## Prepare Data<br>\n",
    "\n",
    "<font size = 4>\n",
    "\n",
    "**Following steps in preparing data:** <br>\n",
    "    \n",
    "- Use `ImageGenerator` class to normalize the data\n",
    "- Use `flow_from_directory` to load images and their classes\n",
    "\n",
    "[`ImageGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da690e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = dpath + \"train\"\n",
    "testDir = dpath + \"test\"\n",
    "trainDir, testDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee86a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images\n",
    "trainGen = ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images\n",
    "testGen = ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad95c582",
   "metadata": {},
   "source": [
    "## Load Data<br>\n",
    "<font size = 4>\n",
    "\n",
    "\n",
    "Parameters to use from the `flow_from_directory()`:\n",
    "- `directory`    - the file path of the target directory for images\n",
    "- `target_size`  - the target image size that we want in our dataset\n",
    "- `batch_size`   - how many images we want to load at a time, e.g. `default is 32`, load 32 images and their labels\n",
    "- `class_mode`   - One hot encoded labels `categorical` is default\n",
    "\n",
    "[`tf.keras.preprocessing` Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data\")\n",
    "trainData = trainGen.flow_from_directory(trainDir,\n",
    "                                         target_size = IMAGE_SHAPE,\n",
    "                                         batch_size = BATCH_SIZE,\n",
    "                                         class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75932835",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Data\")\n",
    "testData = testGen.flow_from_directory(testDir,\n",
    "                                      target_size = IMAGE_SHAPE,\n",
    "                                      batch_size = BATCH_SIZE,\n",
    "                                      class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d20f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c05eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1dfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of batch data (taking one batch - size is 32)\n",
    "images, labels = trainData[0]\n",
    "print(labels, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c355b",
   "metadata": {},
   "source": [
    "Label above is `one hot encoded` `[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]`is `grilled_salmon`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042a944",
   "metadata": {},
   "source": [
    "## Create Models using Tensorflow Hub<br>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "- Until now we have built our models from scratch where we have defined our neural network layers\n",
    "- Follow similar process of creating layers, except the layers are going to come from [Tensorflow Hub](https://tfhub.dev)\n",
    "\n",
    "- Use model from tensorflow hub call [EfficientNet](https://arxiv.org/abs/1905.11946)\n",
    "    \n",
    "Typically these are the steps to follow when selecting a model:\n",
    "1. Go to [Tensorflow Hub](https://tfhub.dev)\n",
    "2. Select problem domain (here it is image processing)\n",
    "3. Doing classification here\n",
    "4. Check out the different models that are available\n",
    "5. Select a particular model then checkout different versions\n",
    "6. Check out which version suites the data set image size (here it is `224`)\n",
    "    \n",
    "    \n",
    "[EfficientNet](https://tfhub.dev/google/collections/efficientnet/1)\n",
    "\n",
    "[EfficientNet v1](https://tfhub.dev/google/collections/efficientnet_v2/1)\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ed6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 of the model\n",
    "\n",
    "effNetURL = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "\n",
    "# version 2 of the model\n",
    "#effNetURL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9721d26",
   "metadata": {},
   "source": [
    "## Feature Extraction Transfer Learning<br>\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "- Here use the underlying `patterns (weights)` that have been learnt by the `pre-defined model` and apply it to `our output classes`\n",
    "- `EfficientNetB0 has 236 layers` and has been `trained on 1000 classes`\n",
    "- To use it for our data, `remove certain layer(s)` and `replace it with a layer` that has the `right number of output classes` in our dataset\n",
    "- `Few layers become trainable`, the `rest of the layers are frozen`\n",
    "- `Technique is useful when our data is similar` to the data that the model was trained on\n",
    "    \n",
    "</font>\n",
    "\n",
    "## Using predefined model<br>\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "- The URL above are saved pretained models on tensorflow hub\n",
    "- When we use these models, they are automatically downloaded\n",
    "- Need `KerasLayer()` from the tensorflow hub library\n",
    "- Write a function that creates a model using the keras layer\n",
    "\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33958bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model\n",
    "def createModel(modelUrl, numClasses = 10):\n",
    "    \"\"\"\n",
    "    Takes a tensorflow hub url and create a Keras Sequential model\n",
    "    \n",
    "    Args:\n",
    "      modelUrl (string): URL for feature extraction\n",
    "      numClasses (int): number of neurons in the output layer i.e. number of classes\n",
    "      \n",
    "    Returns:\n",
    "      An uncompiled Keras Sequential model\n",
    "    \"\"\"\n",
    "    \n",
    "    # download the predefined model  from URL and save as Keras Layer\n",
    "    # Shape is defined as 2D, but images are colored, hence we have\n",
    "    # to add dimension of 3, and the rest is for batch\n",
    "    featureExtractLayer = hub.KerasLayer(modelUrl,\n",
    "                                        trainable = False, # freeze the layers\n",
    "                                        name = 'feature_extraction_layer', \n",
    "                                        input_shape = IMAGE_SHAPE + (3,))\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        featureExtractLayer,                # use as base\n",
    "        layers.Dense(numClasses, activation = 'softmax', name = \"output_layer\")\n",
    "    ],name = \"FeatureExtraction\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1704746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the validation and training data separately\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b47f3",
   "metadata": {},
   "source": [
    "## Model creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "effNetModel = createModel(effNetURL, numClasses = len(trainData.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ca704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "effNetModel.compile(loss = \"categorical_crossentropy\",\n",
    "                   optimizer = tf.keras.optimizers.Adam(),\n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36268c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "effNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(trainData), len(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model (could take upto 24+ minutes)\n",
    "effNetHistory = effNetModel.fit(trainData,\n",
    "                               epochs = 5,\n",
    "                               steps_per_epoch = len(trainData),\n",
    "                               validation_data = testData,\n",
    "                               validation_steps = len(testData),\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8954f",
   "metadata": {},
   "source": [
    "## Model Peformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(effNetHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "effNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa503754",
   "metadata": {},
   "outputs": [],
   "source": [
    "effNetModel.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f79acf",
   "metadata": {},
   "source": [
    "<font color = 'steelblue'>\n",
    "<font size = 4>\n",
    "\n",
    "How cool is it! <br><br>\n",
    "- Both accuracy and validation accuracy *`85% or more`*, just using predefined model\n",
    "- Also, there was more validation data then training data !\n",
    "- With couple of lines of code, leverage *`state of the art`* model\n",
    "    \n",
    "</font>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
